{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KSKUSQBAMDNI",
    "outputId": "da978298-c521-4442-cc1d-e7e924ba71c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "O9d5WCD-M4be"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/content/drive/MyDrive/courses/21_fall/ML/project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow in /home/hx759/.local/lib/python3.8/site-packages (2.7.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/hx759/.local/lib/python3.8/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/hx759/.local/lib/python3.8/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/hx759/.local/lib/python3.8/site-packages (from tensorflow) (1.13.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/hx759/.local/lib/python3.8/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/hx759/.local/lib/python3.8/site-packages (from tensorflow) (1.42.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.32.0 in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from tensorflow) (0.35.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /home/hx759/.local/lib/python3.8/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/hx759/.local/lib/python3.8/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /home/hx759/.local/lib/python3.8/site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: tensorboard~=2.6 in /home/hx759/.local/lib/python3.8/site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /home/hx759/.local/lib/python3.8/site-packages (from tensorflow) (2.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /home/hx759/.local/lib/python3.8/site-packages (from tensorflow) (0.23.0)\n",
      "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /home/hx759/.local/lib/python3.8/site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages/numpy-1.19.2-py3.8-linux-x86_64.egg (from tensorflow) (1.19.2)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/hx759/.local/lib/python3.8/site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: libclang>=9.0.1 in /home/hx759/.local/lib/python3.8/site-packages (from tensorflow) (12.0.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/hx759/.local/lib/python3.8/site-packages (from tensorflow) (3.10.0.2)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /home/hx759/.local/lib/python3.8/site-packages (from tensorflow) (3.19.1)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from tensorflow) (0.13.0)\n",
      "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /home/hx759/.local/lib/python3.8/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/hx759/.local/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/hx759/.local/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/hx759/.local/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (49.2.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (2.24.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/hx759/.local/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (2.3.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/hx759/.local/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/hx759/.local/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (3.3.6)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/hx759/.local/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.25.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/hx759/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/hx759/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /home/hx759/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.8)\n",
      "Requirement already satisfied: importlib-metadata>=4.4; python_version < \"3.10\" in /home/hx759/.local/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow) (4.8.2)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/hx759/.local/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/hx759/.local/lib/python3.8/site-packages (from importlib-metadata>=4.4; python_version < \"3.10\"->markdown>=2.6.8->tensorboard~=2.6->tensorflow) (3.6.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/share/apps/python/3.8.6/intel/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "gbdRYkjqk-CQ"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import sys\n",
    "import h5py\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "6inpmrsTQxat"
   },
   "outputs": [],
   "source": [
    "def data_loader(filepath):\n",
    "    data = h5py.File(filepath, 'r')\n",
    "    x_data = np.array(data['data'])\n",
    "    y_data = np.array(data['label'])\n",
    "    x_data = x_data.transpose((0, 2, 3, 1))\n",
    "\n",
    "    return x_data, y_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "DZuONY7U0y2o"
   },
   "outputs": [],
   "source": [
    "def data_preprocess(x_data):\n",
    "    return x_data/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "h1ISbHifzktQ"
   },
   "outputs": [],
   "source": [
    "clean_data_filename = './clean_validation_data.h5'\n",
    "clean_testdata_filename = './clean_test_data.h5'\n",
    "\n",
    "poisoned_data_filename_1 = './multi/eyebrows_poisoned_data.h5'\n",
    "poisoned_data_filename_2 = './multi/lipstick_poisoned_data.h5'\n",
    "poisoned_data_filename_3 = './multi/sunglasses_poisoned_data.h5'\n",
    "\n",
    "model_filename = './multi/multi_trigger_multi_target_bd_net.h5'\n",
    "\n",
    "cl_x_valid, cl_y_valid = data_loader(clean_data_filename)\n",
    "cl_x_valid = data_preprocess(cl_x_valid)\n",
    "cl_x_test, cl_y_test = data_loader(clean_testdata_filename)\n",
    "cl_x_test = data_preprocess(cl_x_test)\n",
    "\n",
    "eyebrows_x_test, eyebrows_y_test = data_loader(poisoned_data_filename_1)\n",
    "eyebrows_x_test = data_preprocess(eyebrows_x_test)\n",
    "lipstick_x_test, lipstick_y_test = data_loader(poisoned_data_filename_2)\n",
    "lipstick_x_test = data_preprocess(lipstick_x_test)\n",
    "sunglasses_x_test, sunglasses_y_test = data_loader(poisoned_data_filename_3)\n",
    "sunglasses_x_test = data_preprocess(sunglasses_x_test)\n",
    "\n",
    "net = keras.models.load_model(model_filename)\n",
    "#net.load_weights('./multi/multi_trigger_multi_target_bd_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "AN3IawUo5z-C"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "01YqOQLf8kVe",
    "outputId": "a0a54384-8670-4c43-c5fb-125de48747e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11547, 5, 4, 60)\n"
     ]
    }
   ],
   "source": [
    "pool3 = net.get_layer('pool_3').output\n",
    "pool3_net = keras.models.Model(net.input, pool3)\n",
    "activation_all = pool3_net.predict(cl_x_valid)\n",
    "print(activation_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G6_HAqfB9imy",
    "outputId": "c69f9830-744e-42b0-f703-583d2a5c8d2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60,)\n"
     ]
    }
   ],
   "source": [
    "activation = np.mean(activation_all, axis=(0,1,2))\n",
    "print(activation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jUZ6ewnAFHny",
    "outputId": "8b9ad0d5-cf92-49fb-9c3b-5592b00be5ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Classification accuracy: 96.26742876937733\n"
     ]
    }
   ],
   "source": [
    "cl_label_or = np.argmax(net.predict(cl_x_valid), axis=1)\n",
    "or_accuracy = np.mean(np.equal(cl_label_or, cl_y_valid))*100\n",
    "print('Original Classification accuracy:', or_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7GL2N23cnhL3"
   },
   "source": [
    "Prune the b model according to the activation value of pooling layer. I set the channel threshold to 25, which means when the model will prune 25 channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "20ZHfcom9seN",
    "outputId": "8af5d2f0-8757-4a1c-8a06-d54478f51d66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pruned channel: 32\n",
      "Clean Valid Classification accuracy: 96.26742876937733\n",
      "pruned channel: 17\n",
      "Clean Valid Classification accuracy: 96.26742876937733\n",
      "pruned channel: 26\n",
      "Clean Valid Classification accuracy: 96.26742876937733\n",
      "pruned channel: 57\n",
      "Clean Valid Classification accuracy: 96.26742876937733\n",
      "pruned channel: 33\n",
      "Clean Valid Classification accuracy: 96.27608902745301\n",
      "pruned channel: 19\n",
      "Clean Valid Classification accuracy: 96.30206980168009\n",
      "pruned channel: 29\n",
      "Clean Valid Classification accuracy: 96.25010825322595\n",
      "pruned channel: 34\n",
      "Clean Valid Classification accuracy: 96.1981467047718\n",
      "pruned channel: 51\n",
      "Clean Valid Classification accuracy: 96.16350567246904\n",
      "pruned channel: 52\n",
      "Clean Valid Classification accuracy: 95.9210184463497\n",
      "pruned channel: 53\n",
      "Clean Valid Classification accuracy: 94.92508876764528\n",
      "pruned channel: 41\n",
      "Clean Valid Classification accuracy: 94.84714644496405\n",
      "pruned channel: 16\n",
      "Clean Valid Classification accuracy: 94.75188360613146\n",
      "pruned channel: 43\n",
      "Clean Valid Classification accuracy: 94.73456308998009\n",
      "pruned channel: 49\n",
      "Clean Valid Classification accuracy: 94.57001818654196\n",
      "pruned channel: 3\n",
      "Clean Valid Classification accuracy: 94.14566554083311\n",
      "pruned channel: 58\n",
      "Clean Valid Classification accuracy: 93.15839612020437\n",
      "pruned channel: 35\n",
      "Clean Valid Classification accuracy: 92.84662682947952\n",
      "pruned channel: 4\n",
      "Clean Valid Classification accuracy: 92.53485753875465\n",
      "pruned channel: 12\n",
      "Clean Valid Classification accuracy: 92.31835108686239\n",
      "pruned channel: 15\n",
      "Clean Valid Classification accuracy: 90.6382610201784\n",
      "pruned channel: 55\n",
      "Clean Valid Classification accuracy: 89.4258248895817\n",
      "pruned channel: 20\n",
      "Clean Valid Classification accuracy: 86.88836927340434\n",
      "pruned channel: 18\n",
      "Clean Valid Classification accuracy: 83.8832597211397\n"
     ]
    }
   ],
   "source": [
    "#channel_threshold = 27\n",
    "acc_threshold = 10\n",
    "\n",
    "seq_sort = np.argsort(activation)\n",
    "\n",
    "#conv3 = net.get_layer(\"conv_3\")\n",
    "#weight,bias = conv3.get_weights()\n",
    "\n",
    "for i in range(60):\n",
    "    channel = seq_sort[i]\n",
    "\n",
    "    conv3 = net.get_layer(\"conv_3\")\n",
    "    weight,bias = conv3.get_weights()\n",
    "    weight[:, :, :, channel] = 0. \n",
    "    bias[channel] = 0.\n",
    "    conv3.set_weights((weight,bias))\n",
    "    print(\"pruned channel:\", channel)\n",
    "    \n",
    "    cl_label_v = np.argmax(net.predict(cl_x_valid), axis=1)\n",
    "    valid_accuracy = np.mean(np.equal(cl_label_v, cl_y_valid))*100\n",
    "    print('Clean Valid Classification accuracy:', valid_accuracy)\n",
    "\n",
    "    if valid_accuracy < or_accuracy-acc_threshold:\n",
    "      net.save(\"multi pruned model.h5\")\n",
    "      break\n",
    "    \n",
    "#net.save(\"sunglasses pruned model.h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xxjdb838vCum"
   },
   "source": [
    "Fine tune the pruned model b prime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RTeSVj2YvGAf"
   },
   "outputs": [],
   "source": [
    "train_data_filename = './clean_validation_data.h5'\n",
    "model_filename = './multi pruned model.h5'\n",
    "\n",
    "x_train, y_train = data_loader(train_data_filename)\n",
    "x_train = data_preprocess(x_train)\n",
    "\n",
    "net = keras.models.load_model(model_filename)\n",
    "\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "net.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])\n",
    "\n",
    "net.fit(x_train, y_train, epochs = 50)\n",
    "net.save(\"multi fine-pruning model.h5\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "gi9oa6yy1Dru"
   },
   "source": [
    "The Fine-Pruning G net is the one compare the B net and Fine-Pruning B net. The clean acc and attack success rate is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data_filename = './clean_test_data.h5'\n",
    "\n",
    "model_filename = './multi/multi_trigger_multi_target_bd_net.h5'\n",
    "b_prime_model_filename = \"./multi fine-pruning model.h5\"\n",
    "\n",
    "cl_x_test, cl_y_test = data_loader(clean_data_filename)\n",
    "cl_x_test = data_preprocess(cl_x_test)\n",
    "\n",
    "\n",
    "net = keras.models.load_model(model_filename)\n",
    "b_prime_net = keras.models.load_model(b_prime_model_filename)\n",
    "\n",
    "cl_b = np.argmax(net.predict(cl_x_test), axis=1)\n",
    "cl_b_p = np.argmax(b_prime_net.predict(cl_x_test), axis=1)\n",
    "cl_g = []\n",
    "for x1, x2 in zip(cl_b, cl_b_p):\n",
    "    if x1 == x2:\n",
    "        cl_g.append(x1)\n",
    "    else:\n",
    "        cl_g.append(1283)\n",
    "\n",
    "cl_g_acc = np.mean(np.equal(cl_g, cl_y_test))*100\n",
    "print('Clean Classification accuracy for fine-pruning G net:', cl_g_acc)\n",
    "    \n",
    "    \n",
    "    \n",
    "eyebrows_bd_b = np.argmax(net.predict(eyebrows_x_test), axis=1)\n",
    "eyebrows_bd_b_p = np.argmax(b_prime_net.predict(eyebrows_x_test), axis=1)\n",
    "eyebrows_bd_g = []\n",
    "for x1, x2 in zip(eyebrows_bd_b, eyebrows_bd_b_p):\n",
    "    if x1 == x2:\n",
    "        eyebrows_bd_g.append(x1)\n",
    "    else:\n",
    "        eyebrows_bd_g.append(1283)\n",
    "        \n",
    "eyebrows_asr = np.mean(np.equal(eyebrows_bd_g, eyebrows_y_test))*100\n",
    "print('Attack Success Rate for fine-pruning G net on eyebrows poisoned data:', eyebrows_asr)\n",
    "\n",
    "\n",
    "lipstick_bd_b = np.argmax(net.predict(lipstick_x_test), axis=1)\n",
    "lipstick_bd_b_p = np.argmax(b_prime_net.predict(lipstick_x_test), axis=1)\n",
    "lipstick_bd_g = []\n",
    "for x1, x2 in zip(lipstick_bd_b, lipstick_bd_b_p):\n",
    "    if x1 == x2:\n",
    "        lipstick_bd_g.append(x1)\n",
    "    else:\n",
    "        lipstick_bd_g.append(1283)\n",
    "        \n",
    "lipstick_asr = np.mean(np.equal(lipstick_bd_g, lipstick_y_test))*100\n",
    "print('Attack Success Rate for fine-pruning G net on lipstick poisoned data:', lipstick_asr)\n",
    "\n",
    "\n",
    "sunglasses_bd_b = np.argmax(net.predict(sunglasses_x_test), axis=1)\n",
    "sunglasses_bd_b_p = np.argmax(b_prime_net.predict(sunglasses_x_test), axis=1)\n",
    "sunglasses_bd_g = []\n",
    "for x1, x2 in zip(sunglasses_bd_b, sunglasses_bd_b_p):\n",
    "    if x1 == x2:\n",
    "        sunglasses_bd_g.append(x1)\n",
    "    else:\n",
    "        sunglasses_bd_g.append(1283)\n",
    "        \n",
    "sunglasses_asr = np.mean(np.equal(sunglasses_bd_g, sunglasses_y_test))*100\n",
    "print('Attack Success Rate for fine-pruning G net on sunglasses poisoned data:', sunglasses_asr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "21fall_MLCyber_project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
